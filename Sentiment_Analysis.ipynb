{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOl8W9L4Qr6q2pqF4WuZOEt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Roxxxers/TSIN01/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDLxqZ-6Fa4V"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "#https://www.kaggle.com/arhamrumi/amazon-product-reviews\n",
        "#https://www.kaggle.com/skathirmani/amazon-reviews"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWV3k_2UpNxh"
      },
      "source": [
        "# 1.0 Import the reviews and modules\n",
        "Here we import the modules and files that we are going to use, we also print a heatmap to see if there are any null values in the dataframe\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMN6Fgb7FhUY"
      },
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "#--------------------------------------TRAIN--------------------------------------#\n",
        "\n",
        "Train_Reviews = pd.read_csv(\"/content/drive/MyDrive/TDDE16 PROJEKT/reviews/amazon/amazon_reviews_big.csv\", usecols = [\"overall\", \"reviewText\"])\n",
        "\n",
        "Train_Reviews = Train_Reviews.rename(columns={\"reviewText\": \"Text\", \"overall\": \"Score\"})\n",
        "Train_Reviews['Text'] = Train_Reviews['Text'].astype('U').values\n",
        "\n",
        "#--------------------------------------TEST--------------------------------------#\n",
        "\n",
        "test_reviews = pd.read_csv(\"/content/drive/MyDrive/TDDE16 PROJEKT/reviews/amazon/Reviews.csv\", usecols = [\"Text\", \"Score\"])\n",
        "\n",
        "test_reviews['Score'] = test_reviews['Score'].fillna(0).astype(int)\n",
        "test_reviews['Text'] = test_reviews['Text'].astype('U').values\n",
        "\n",
        "#--------------------------------------------------------------------------------#\n",
        "\n",
        "test_reviews\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt8_mb3NNoJc"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import numpy as np\n",
        "\n",
        "def print_CM(Test,pred):\n",
        "  cm = confusion_matrix(pred, Test)\n",
        "  plt.figure(figsize=(7,7))\n",
        "  sn.heatmap(cm, annot=True)\n",
        "  plt.xlabel(\"Predicted\")\n",
        "  plt.ylabel(\"Truth\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FketGAv24qwi"
      },
      "source": [
        "# 1.1 Preprocessing\n",
        "\n",
        "In this section we will be preprocessing the dataframe and remove all the noise from the reviews to see how the noise affect the f1-score of the classifiers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAieCusylGkp"
      },
      "source": [
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "#Tagger, parser and entity are disabled since they are not needed for this problem. Disable them will increases performance.\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\", \"entity\"]) \n",
        "\n",
        "#Will return words in its lemma form as long as they are not stop words or non-alphabetic.\n",
        "def preprocess(text):\n",
        "    doc = nlp(text)\n",
        "    return [token.lemma_ for token in doc if not token.is_stop and token.lemma_.isalpha()]\n",
        "\n",
        "def df_preprocess(df):\n",
        "  for index, row in df.iterrows():\n",
        "    desc = preprocess(row[\"Text\"])\n",
        "    desc = \" \".join(desc).lower()\n",
        "    df.append([desc, row[\"Score\"]])\n",
        "\n",
        "  return df\n",
        "\n",
        "test = df_preprocess(test_reviews)\n",
        "training = df_preprocess(Train_Reviews)\n",
        "\n",
        "test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2phMGCU2IxzV"
      },
      "source": [
        " \n",
        "#remove last row as it contains a NaN value\n",
        "test.drop(test.tail().index,inplace=True)\n",
        "\n",
        "copy_test = test.copy(deep=True)\n",
        "copy_training = training.copy(deep=True)\n",
        "\n",
        "#Replace the values of 1-2 to negative, 3 to neutral and 4-5 to positive. \n",
        "copy_test = copy_test.replace({\"Score\" : {1 : \"Negative\", 2 : \"Negative\", 3 : \"Neutral\", 4 : \"Positive\", 5 : \"Positive\"}})\n",
        "copy_training = copy_training.replace({\"Score\" : {1 : \"Negative\", 2 : \"Negative\", 3 : \"Neutral\", 4 : \"Positive\", 5 : \"Positive\"}})\n",
        "\n",
        "copy_test.drop(copy_test.loc[copy_test['Score']==\"Neutral\"].index, inplace=True)\n",
        "copy_training.drop(copy_training.loc[copy_training['Score']==\"Neutral\"].index, inplace=True)\n",
        "\n",
        "\n",
        "copy_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icslgNaPpUxU"
      },
      "source": [
        "# 2.0 Baseline\n",
        "For our testing we need to create a baseline with the different classifiers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4HWfA65_B3B"
      },
      "source": [
        "2.0.1 Baseline values\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxTv_sWfXhZW"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "descTrain, ResponseTrain = copy_training['Text'], copy_training['Score'] \n",
        "descTest, ResponseTest =  copy_test['Text'], copy_test['Score'] \n",
        "\n",
        "#Response = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
        "Response = [\"Negative\", \"Positive\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeY-4fBklWMr"
      },
      "source": [
        "## 2.1 Naive Baysian\n",
        "\n",
        "In this section we will be conduction different tests with the Naive baysian classifier. I will be testing the Multinomial and Bernoulli classifiers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0fhfQB_V2Qm"
      },
      "source": [
        "2.1.1 Naive Baysian Multinomial\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e09MvpUrTAC"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "pipe = Pipeline([('vectorizer', CountVectorizer()), ('MultinomialNB', MultinomialNB())]).fit(descTrain, ResponseTrain)\n",
        "pred = pipe.predict(descTest)\n",
        "\n",
        "print(classification_report(ResponseTest, pred, target_names=Response))\n",
        "\n",
        "print_CM(ResponseTest,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY5S25mxasHX"
      },
      "source": [
        "2.1.2 Naive Baysian Bernoulli"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l461sGDZayW-"
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "pipe = Pipeline([('vectorizer', CountVectorizer()), ('BernoulliNB', BernoulliNB())]).fit(descTrain, ResponseTrain)\n",
        "pred = pipe.predict(descTest)\n",
        "\n",
        "print(classification_report(ResponseTest, pred, target_names=Response))\n",
        "print_CM(ResponseTest,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KadmP1QaWExk"
      },
      "source": [
        "## 2.2 Random Forest \n",
        "\n",
        "In this section we will be conduction different tests with the Random forest classifier. I will be testing with different trees, 50, 100 and 200 trees\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkKqdtjabyOs"
      },
      "source": [
        "2.2.1 Random forest 50 trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbZlIfC56-2h"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "pipe = Pipeline([('vectorizer', CountVectorizer()), ('RandomForestClassifier', RandomForestClassifier(n_estimators=50))]).fit(descTrain, ResponseTrain)\n",
        "pred = pipe.predict(descTest)\n",
        "\n",
        "print(classification_report(ResponseTest, pred, target_names=Response))\n",
        "print_CM(ResponseTest,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6aaX6oPb2n8"
      },
      "source": [
        "2.2.2 Random forest 100 trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pJtLbNmb7VV"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "pipe = Pipeline([('vectorizer', CountVectorizer()), ('RandomForestClassifier', RandomForestClassifier(n_estimators=100))]).fit(descTrain, ResponseTrain)\n",
        "pred = pipe.predict(descTest)\n",
        "\n",
        "print(classification_report(ResponseTest, pred, target_names=Response))\n",
        "print_CM(ResponseTest,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIYXPOmob4c9"
      },
      "source": [
        "2.2.3 Random forest 200 trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IxRzbxzb8LU"
      },
      "source": [
        "pipe = Pipeline([('vectorizer', CountVectorizer()), ('RandomForestClassifier', RandomForestClassifier(n_estimators=200))]).fit(descTrain, ResponseTrain)\n",
        "pred = pipe.predict(descTest)\n",
        "\n",
        "print(classification_report(ResponseTest, pred, target_names=Response))\n",
        "print_CM(ResponseTest,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsIExTMXWJY2"
      },
      "source": [
        "## 2.3 Support Vector Machine\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3gypasW3DvV"
      },
      "source": [
        "2.3.1 C-Support Vector Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqS8Z_XNskrC"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "pipe = Pipeline([('vectorizer', CountVectorizer()), ('SVC', SVC())]).fit(descTrain, ResponseTrain)\n",
        "pred = pipe.predict(descTest)\n",
        "\n",
        "print(classification_report(ResponseTest, pred, target_names=Response))\n",
        "print_CM(ResponseTest,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBAf5k_W2_wv"
      },
      "source": [
        "2.3.2 Linear Support Vector Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4gqm5XA3M1F"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "pipe = Pipeline([('vectorizer', CountVectorizer()), ('LinearSVC', LinearSVC(dual=False))]).fit(descTrain, ResponseTrain)\n",
        "pred = pipe.predict(descTest)\n",
        "\n",
        "print(classification_report(ResponseTest, pred, target_names=Response))\n",
        "print_CM(ResponseTest,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdKpSN89_ZV4"
      },
      "source": [
        "# 3.0 Balanced data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pnuSYau_iCl"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "resampled = []\n",
        "minority_sample = ResponseTrain.value_counts()[-1]\n",
        "\n",
        "for val in Response:\n",
        "    resampled.append(copy_training[ResponseTrain == val][:minority_sample]) #Append speeches for each party where partTrain == party until count=minority_sample(719)\n",
        "\n",
        "resampled_training = pd.concat(resampled, ignore_index=True)\n",
        "#print(resampled_training['Score'].value_counts())\n",
        "\n",
        "resampled_training = df_preprocess(resampled_training)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iwgg57KoGt0H"
      },
      "source": [
        "## 3.1 Naive Baysian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RalKGHhHB-7"
      },
      "source": [
        "3.1.1 Naive Baysian Multinomial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie5hQ1ivAPFT"
      },
      "source": [
        "pipe = Pipeline([('vectorizer', CountVectorizer()), ('MultinomialNB', MultinomialNB())]).fit(resampled_training[\"Text\"], resampled_training[\"Score\"])\n",
        "pred = pipe.predict(descTest)\n",
        "\n",
        "print(classification_report(ResponseTest, pred, target_names=Response))\n",
        "\n",
        "print_CM(ResponseTest,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlcAHcEbJ6BD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tMKn47CHHgC"
      },
      "source": [
        "3.1.2 Naive Baysian Bernoulli"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpwlaUT7BLs8"
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "pipe = Pipeline([('vectorizer', CountVectorizer()), ('BernoulliNB', BernoulliNB())]).fit(resampled_training[\"Text\"], resampled_training[\"Score\"])\n",
        "pred = pipe.predict(descTest)\n",
        "\n",
        "print(classification_report(ResponseTest, pred, target_names=Response))\n",
        "print_CM(ResponseTest,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSfnfoKKHVMF"
      },
      "source": [
        "## 3.2 Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6Q_NzVIHbuy"
      },
      "source": [
        "3.2.1 Random Forest 50 trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj6afogaHiD4"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "pipe = Pipeline([('vectorizer', CountVectorizer()), ('RandomForestClassifier', RandomForestClassifier(n_estimators=50))]).fit(resampled_training[\"Text\"], resampled_training[\"Score\"])\n",
        "pred = pipe.predict(descTest)\n",
        "\n",
        "print(classification_report(ResponseTest, pred, target_names=Response))\n",
        "print_CM(ResponseTest,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gj370DQAHicd"
      },
      "source": [
        "3.2.2 Random Forest 100 trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz9H70R4HlAs"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "pipe = Pipeline([('vectorizer', CountVectorizer()), ('RandomForestClassifier', RandomForestClassifier(n_estimators=100))]).fit(resampled_training[\"Text\"], resampled_training[\"Score\"])\n",
        "pred = pipe.predict(descTest)\n",
        "\n",
        "print(classification_report(ResponseTest, pred, target_names=Response))\n",
        "print_CM(ResponseTest,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjkJ72nBHlT4"
      },
      "source": [
        "3.2.3 Random Forest 200 trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtFLDguDHwMe"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "pipe = Pipeline([('vectorizer', CountVectorizer()), ('RandomForestClassifier', RandomForestClassifier(n_estimators=200))]).fit(resampled_training[\"Text\"], resampled_training[\"Score\"])\n",
        "pred = pipe.predict(descTest)\n",
        "\n",
        "print(classification_report(ResponseTest, pred, target_names=Response))\n",
        "print_CM(ResponseTest,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAVQRtHuHwoG"
      },
      "source": [
        "## 3.3 Support Vector Machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xc8Mt-VKH60p"
      },
      "source": [
        "3.2.1 C-Support Vector Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACjSMizXIAzO"
      },
      "source": [
        "pipe = Pipeline([('vectorizer', CountVectorizer()), ('SVC', SVC())]).fit(resampled_training[\"Text\"], resampled_training[\"Score\"])\n",
        "pred = pipe.predict(descTest)\n",
        "\n",
        "print(classification_report(ResponseTest, pred, target_names=Response))\n",
        "print_CM(ResponseTest,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXEHmLXIIBHT"
      },
      "source": [
        "3.2.2 Linear Support Vector Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co8m42TlII-l"
      },
      "source": [
        "pipe = Pipeline([('vectorizer', CountVectorizer()), ('LinearSVC', LinearSVC(dual=False))]).fit(resampled_training[\"Text\"], resampled_training[\"Score\"])\n",
        "pred = pipe.predict(descTest)\n",
        "\n",
        "print(classification_report(ResponseTest, pred, target_names=Response))\n",
        "print_CM(ResponseTest,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ENSiONuyekL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}